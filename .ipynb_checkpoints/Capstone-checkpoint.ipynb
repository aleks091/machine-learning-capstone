{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "## Capstone Project: Classification of retinal optical coherence tomography diagnosis\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Step 0: Verify TensorFlow is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\microsoft visual studio\\shared\\anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 1: Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 total oct categories.\n",
      "There are 4562 total oct images.\n",
      "\n",
      "There are 2624 training oct images.\n",
      "There are 938 validation oct images.\n",
      "There are 1000 test oct images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    oct_files = np.array(data['filenames'])\n",
    "    oct_targets = np_utils.to_categorical(np.array(data['target']), 4)\n",
    "    return oct_files, oct_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('OCT2017-REDUCED/train')\n",
    "valid_files, valid_targets = load_dataset('OCT2017-REDUCED/valid')\n",
    "test_files, test_targets = load_dataset('OCT2017-REDUCED/test')\n",
    "\n",
    "# load list of oct names\n",
    "oct_names = [item[20:-1] for item in sorted(glob(\"OCT2017-REDUCED/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total oct categories.' % len(oct_names))\n",
    "print('There are %s total oct images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training oct images.' % len(train_files))\n",
    "print('There are %d validation oct images.' % len(valid_files))\n",
    "print('There are %d test oct images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2624/2624 [00:10<00:00, 242.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 938/938 [00:03<00:00, 246.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:03<00:00, 313.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step0'></a>\n",
    "## Step N: Create benchmark model\n",
    "\n",
    "### Import Dog Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of dog images.  We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `dog_names` - list of string-valued dog breed names for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 75)      975       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 75)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 100)     30100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 125)       50125     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 125)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 125)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 98000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 392004    \n",
      "=================================================================\n",
      "Total params: 473,204\n",
      "Trainable params: 473,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model = Sequential([\n",
    "    \n",
    "    #Locally connected layer containing fewer weights\n",
    "    #Break the image up into smaller pieces\n",
    "    #Use 75 filters to identify the most general patterns\n",
    "    #Use standard kerner_size of 2\n",
    "    Conv2D(filters=75, kernel_size=2, padding='same', activation='relu', input_shape=(224,224,3)),\n",
    "    \n",
    "    #Reduce dimensionality of convolutional layer,\n",
    "    #Reduce by taking the maximum value in the filter\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    #Use 100 filters to identify the more specific patterns\n",
    "    #Use standard kerner_size of 2\n",
    "    Conv2D(filters=100, kernel_size=2, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    #Use 125 filters to identify the more specific patterns\n",
    "    #Use standard kerner_size of 2\n",
    "    Conv2D(filters=125, kernel_size=2, padding='same', activation='relu'),\n",
    "    \n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Conv2D(filters=125, kernel_size=2, padding='same', activation='relu'),    \n",
    "    #MaxPooling2D(pool_size=2),\n",
    "    #Conv2D(filters=125, kernel_size=2, padding='same', activation='relu'),    \n",
    "    #MaxPooling2D(pool_size=2),\n",
    "    #Conv2D(filters=125, kernel_size=2, padding='same', activation='relu'),    \n",
    "    #MaxPooling2D(pool_size=2),    \n",
    "    #Conv2D(filters=125, kernel_size=2, padding='same', activation='relu'),    \n",
    "    #MaxPooling2D(pool_size=2),\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    Dropout(0.3),\n",
    "    Flatten(),\n",
    "    # Add a softmax activation layer\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2624 samples, validate on 938 samples\n",
      "Epoch 1/4\n",
      "2624/2624 [==============================] - ETA: 5:37 - loss: 1.3808 - acc: 0.300 - ETA: 3:12 - loss: 2.4185 - acc: 0.300 - ETA: 2:24 - loss: 2.4598 - acc: 0.283 - ETA: 1:59 - loss: 2.1982 - acc: 0.275 - ETA: 1:45 - loss: 2.0373 - acc: 0.270 - ETA: 1:35 - loss: 1.9316 - acc: 0.250 - ETA: 1:27 - loss: 1.8539 - acc: 0.235 - ETA: 1:22 - loss: 1.7911 - acc: 0.231 - ETA: 1:17 - loss: 1.7459 - acc: 0.233 - ETA: 1:14 - loss: 1.7079 - acc: 0.225 - ETA: 1:11 - loss: 1.6778 - acc: 0.231 - ETA: 1:08 - loss: 1.6540 - acc: 0.237 - ETA: 1:06 - loss: 1.6371 - acc: 0.242 - ETA: 1:04 - loss: 1.6193 - acc: 0.242 - ETA: 1:02 - loss: 1.5997 - acc: 0.250 - ETA: 1:00 - loss: 1.5891 - acc: 0.250 - ETA: 59s - loss: 1.5752 - acc: 0.261 - ETA: 58s - loss: 1.5601 - acc: 0.25 - ETA: 56s - loss: 1.5631 - acc: 0.25 - ETA: 55s - loss: 1.5524 - acc: 0.25 - ETA: 54s - loss: 1.5445 - acc: 0.25 - ETA: 53s - loss: 1.5366 - acc: 0.25 - ETA: 52s - loss: 1.5270 - acc: 0.26 - ETA: 51s - loss: 1.5184 - acc: 0.27 - ETA: 50s - loss: 1.5119 - acc: 0.27 - ETA: 50s - loss: 1.5121 - acc: 0.27 - ETA: 49s - loss: 1.5052 - acc: 0.28 - ETA: 48s - loss: 1.4983 - acc: 0.28 - ETA: 47s - loss: 1.4913 - acc: 0.28 - ETA: 46s - loss: 1.4867 - acc: 0.29 - ETA: 46s - loss: 1.4780 - acc: 0.29 - ETA: 45s - loss: 1.4733 - acc: 0.29 - ETA: 44s - loss: 1.4634 - acc: 0.29 - ETA: 44s - loss: 1.4623 - acc: 0.29 - ETA: 43s - loss: 1.4570 - acc: 0.29 - ETA: 43s - loss: 1.4516 - acc: 0.30 - ETA: 42s - loss: 1.4479 - acc: 0.30 - ETA: 41s - loss: 1.4435 - acc: 0.30 - ETA: 41s - loss: 1.4387 - acc: 0.31 - ETA: 40s - loss: 1.4492 - acc: 0.31 - ETA: 40s - loss: 1.4474 - acc: 0.31 - ETA: 39s - loss: 1.4434 - acc: 0.31 - ETA: 38s - loss: 1.4393 - acc: 0.31 - ETA: 38s - loss: 1.4341 - acc: 0.32 - ETA: 37s - loss: 1.4343 - acc: 0.32 - ETA: 37s - loss: 1.4307 - acc: 0.32 - ETA: 36s - loss: 1.4275 - acc: 0.32 - ETA: 36s - loss: 1.4281 - acc: 0.32 - ETA: 35s - loss: 1.4250 - acc: 0.32 - ETA: 35s - loss: 1.4255 - acc: 0.32 - ETA: 34s - loss: 1.4204 - acc: 0.33 - ETA: 34s - loss: 1.4209 - acc: 0.32 - ETA: 33s - loss: 1.4179 - acc: 0.33 - ETA: 33s - loss: 1.4146 - acc: 0.33 - ETA: 32s - loss: 1.4098 - acc: 0.33 - ETA: 32s - loss: 1.4082 - acc: 0.33 - ETA: 31s - loss: 1.4044 - acc: 0.34 - ETA: 31s - loss: 1.4021 - acc: 0.34 - ETA: 30s - loss: 1.4016 - acc: 0.34 - ETA: 30s - loss: 1.3982 - acc: 0.34 - ETA: 29s - loss: 1.3991 - acc: 0.34 - ETA: 29s - loss: 1.3974 - acc: 0.34 - ETA: 28s - loss: 1.3953 - acc: 0.34 - ETA: 28s - loss: 1.3952 - acc: 0.34 - ETA: 28s - loss: 1.3944 - acc: 0.34 - ETA: 27s - loss: 1.3926 - acc: 0.35 - ETA: 27s - loss: 1.3912 - acc: 0.35 - ETA: 26s - loss: 1.3905 - acc: 0.35 - ETA: 26s - loss: 1.3897 - acc: 0.35 - ETA: 25s - loss: 1.3882 - acc: 0.35 - ETA: 25s - loss: 1.3873 - acc: 0.35 - ETA: 24s - loss: 1.3866 - acc: 0.35 - ETA: 24s - loss: 1.3839 - acc: 0.35 - ETA: 23s - loss: 1.3836 - acc: 0.35 - ETA: 23s - loss: 1.3820 - acc: 0.35 - ETA: 23s - loss: 1.3811 - acc: 0.35 - ETA: 22s - loss: 1.3794 - acc: 0.35 - ETA: 22s - loss: 1.3780 - acc: 0.35 - ETA: 21s - loss: 1.3757 - acc: 0.35 - ETA: 21s - loss: 1.3734 - acc: 0.35 - ETA: 20s - loss: 1.3720 - acc: 0.35 - ETA: 20s - loss: 1.3716 - acc: 0.35 - ETA: 20s - loss: 1.3710 - acc: 0.35 - ETA: 19s - loss: 1.3687 - acc: 0.35 - ETA: 19s - loss: 1.3685 - acc: 0.35 - ETA: 18s - loss: 1.3683 - acc: 0.35 - ETA: 18s - loss: 1.3666 - acc: 0.35 - ETA: 17s - loss: 1.3642 - acc: 0.36 - ETA: 17s - loss: 1.3614 - acc: 0.36 - ETA: 17s - loss: 1.3614 - acc: 0.36 - ETA: 16s - loss: 1.3615 - acc: 0.36 - ETA: 16s - loss: 1.3610 - acc: 0.36 - ETA: 15s - loss: 1.3585 - acc: 0.36 - ETA: 15s - loss: 1.3567 - acc: 0.36 - ETA: 14s - loss: 1.3573 - acc: 0.36 - ETA: 14s - loss: 1.3568 - acc: 0.36 - ETA: 14s - loss: 1.3550 - acc: 0.37 - ETA: 13s - loss: 1.3522 - acc: 0.37 - ETA: 13s - loss: 1.3492 - acc: 0.37 - ETA: 12s - loss: 1.3490 - acc: 0.37 - ETA: 12s - loss: 1.3458 - acc: 0.37 - ETA: 12s - loss: 1.3433 - acc: 0.37 - ETA: 11s - loss: 1.3406 - acc: 0.38 - ETA: 11s - loss: 1.3397 - acc: 0.38 - ETA: 10s - loss: 1.3379 - acc: 0.38 - ETA: 10s - loss: 1.3347 - acc: 0.38 - ETA: 9s - loss: 1.3326 - acc: 0.3827 - ETA: 9s - loss: 1.3313 - acc: 0.383 - ETA: 9s - loss: 1.3301 - acc: 0.385 - ETA: 8s - loss: 1.3310 - acc: 0.385 - ETA: 8s - loss: 1.3304 - acc: 0.384 - ETA: 7s - loss: 1.3311 - acc: 0.383 - ETA: 7s - loss: 1.3299 - acc: 0.384 - ETA: 7s - loss: 1.3281 - acc: 0.385 - ETA: 6s - loss: 1.3266 - acc: 0.386 - ETA: 6s - loss: 1.3256 - acc: 0.386 - ETA: 5s - loss: 1.3247 - acc: 0.387 - ETA: 5s - loss: 1.3227 - acc: 0.388 - ETA: 4s - loss: 1.3206 - acc: 0.390 - ETA: 4s - loss: 1.3200 - acc: 0.391 - ETA: 4s - loss: 1.3187 - acc: 0.392 - ETA: 3s - loss: 1.3170 - acc: 0.393 - ETA: 3s - loss: 1.3159 - acc: 0.393 - ETA: 2s - loss: 1.3171 - acc: 0.392 - ETA: 2s - loss: 1.3170 - acc: 0.391 - ETA: 2s - loss: 1.3159 - acc: 0.392 - ETA: 1s - loss: 1.3129 - acc: 0.394 - ETA: 1s - loss: 1.3127 - acc: 0.393 - ETA: 0s - loss: 1.3106 - acc: 0.395 - ETA: 0s - loss: 1.3098 - acc: 0.396 - ETA: 0s - loss: 1.3096 - acc: 0.396 - 61s 23ms/step - loss: 1.3096 - acc: 0.3967 - val_loss: 1.3514 - val_acc: 0.3284\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.35143, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624/2624 [==============================] - ETA: 51s - loss: 1.1223 - acc: 0.45 - ETA: 50s - loss: 1.1527 - acc: 0.50 - ETA: 49s - loss: 1.0805 - acc: 0.58 - ETA: 49s - loss: 1.1496 - acc: 0.55 - ETA: 49s - loss: 1.1753 - acc: 0.51 - ETA: 48s - loss: 1.1536 - acc: 0.51 - ETA: 48s - loss: 1.1126 - acc: 0.54 - ETA: 47s - loss: 1.0976 - acc: 0.55 - ETA: 47s - loss: 1.1191 - acc: 0.54 - ETA: 47s - loss: 1.1156 - acc: 0.54 - ETA: 46s - loss: 1.0990 - acc: 0.55 - ETA: 46s - loss: 1.0737 - acc: 0.56 - ETA: 45s - loss: 1.0873 - acc: 0.55 - ETA: 45s - loss: 1.0908 - acc: 0.55 - ETA: 45s - loss: 1.0955 - acc: 0.55 - ETA: 44s - loss: 1.1015 - acc: 0.54 - ETA: 44s - loss: 1.0959 - acc: 0.55 - ETA: 44s - loss: 1.0881 - acc: 0.55 - ETA: 43s - loss: 1.0847 - acc: 0.55 - ETA: 43s - loss: 1.0726 - acc: 0.56 - ETA: 42s - loss: 1.0647 - acc: 0.56 - ETA: 42s - loss: 1.0712 - acc: 0.56 - ETA: 42s - loss: 1.0726 - acc: 0.55 - ETA: 41s - loss: 1.0854 - acc: 0.55 - ETA: 41s - loss: 1.0861 - acc: 0.55 - ETA: 40s - loss: 1.0900 - acc: 0.54 - ETA: 40s - loss: 1.0915 - acc: 0.54 - ETA: 39s - loss: 1.0846 - acc: 0.54 - ETA: 39s - loss: 1.0785 - acc: 0.55 - ETA: 39s - loss: 1.0771 - acc: 0.55 - ETA: 38s - loss: 1.0720 - acc: 0.55 - ETA: 38s - loss: 1.0660 - acc: 0.55 - ETA: 38s - loss: 1.0703 - acc: 0.55 - ETA: 37s - loss: 1.0689 - acc: 0.55 - ETA: 37s - loss: 1.0735 - acc: 0.55 - ETA: 36s - loss: 1.0762 - acc: 0.55 - ETA: 36s - loss: 1.0638 - acc: 0.56 - ETA: 36s - loss: 1.0580 - acc: 0.56 - ETA: 35s - loss: 1.0571 - acc: 0.56 - ETA: 35s - loss: 1.0541 - acc: 0.57 - ETA: 34s - loss: 1.0528 - acc: 0.57 - ETA: 34s - loss: 1.0530 - acc: 0.56 - ETA: 34s - loss: 1.0463 - acc: 0.57 - ETA: 33s - loss: 1.0465 - acc: 0.56 - ETA: 33s - loss: 1.0507 - acc: 0.56 - ETA: 33s - loss: 1.0525 - acc: 0.56 - ETA: 32s - loss: 1.0519 - acc: 0.56 - ETA: 32s - loss: 1.0493 - acc: 0.56 - ETA: 31s - loss: 1.0484 - acc: 0.56 - ETA: 31s - loss: 1.0447 - acc: 0.56 - ETA: 31s - loss: 1.0441 - acc: 0.56 - ETA: 30s - loss: 1.0408 - acc: 0.57 - ETA: 30s - loss: 1.0430 - acc: 0.56 - ETA: 29s - loss: 1.0470 - acc: 0.56 - ETA: 29s - loss: 1.0446 - acc: 0.56 - ETA: 29s - loss: 1.0396 - acc: 0.57 - ETA: 28s - loss: 1.0384 - acc: 0.57 - ETA: 28s - loss: 1.0329 - acc: 0.57 - ETA: 28s - loss: 1.0301 - acc: 0.57 - ETA: 27s - loss: 1.0284 - acc: 0.57 - ETA: 27s - loss: 1.0279 - acc: 0.57 - ETA: 26s - loss: 1.0243 - acc: 0.57 - ETA: 26s - loss: 1.0226 - acc: 0.57 - ETA: 26s - loss: 1.0233 - acc: 0.57 - ETA: 25s - loss: 1.0242 - acc: 0.57 - ETA: 25s - loss: 1.0238 - acc: 0.57 - ETA: 24s - loss: 1.0234 - acc: 0.57 - ETA: 24s - loss: 1.0229 - acc: 0.57 - ETA: 24s - loss: 1.0225 - acc: 0.57 - ETA: 23s - loss: 1.0221 - acc: 0.57 - ETA: 23s - loss: 1.0213 - acc: 0.57 - ETA: 23s - loss: 1.0218 - acc: 0.57 - ETA: 22s - loss: 1.0236 - acc: 0.57 - ETA: 22s - loss: 1.0212 - acc: 0.57 - ETA: 21s - loss: 1.0206 - acc: 0.57 - ETA: 21s - loss: 1.0180 - acc: 0.57 - ETA: 21s - loss: 1.0155 - acc: 0.57 - ETA: 20s - loss: 1.0120 - acc: 0.57 - ETA: 20s - loss: 1.0119 - acc: 0.57 - ETA: 19s - loss: 1.0078 - acc: 0.58 - ETA: 19s - loss: 1.0067 - acc: 0.58 - ETA: 19s - loss: 1.0031 - acc: 0.58 - ETA: 18s - loss: 1.0034 - acc: 0.58 - ETA: 18s - loss: 1.0027 - acc: 0.58 - ETA: 17s - loss: 0.9999 - acc: 0.58 - ETA: 17s - loss: 0.9971 - acc: 0.58 - ETA: 17s - loss: 0.9972 - acc: 0.58 - ETA: 16s - loss: 0.9956 - acc: 0.58 - ETA: 16s - loss: 0.9952 - acc: 0.58 - ETA: 16s - loss: 0.9968 - acc: 0.58 - ETA: 15s - loss: 0.9967 - acc: 0.58 - ETA: 15s - loss: 0.9961 - acc: 0.58 - ETA: 14s - loss: 0.9961 - acc: 0.58 - ETA: 14s - loss: 0.9950 - acc: 0.58 - ETA: 14s - loss: 0.9933 - acc: 0.58 - ETA: 13s - loss: 0.9923 - acc: 0.58 - ETA: 13s - loss: 0.9915 - acc: 0.58 - ETA: 12s - loss: 0.9883 - acc: 0.58 - ETA: 12s - loss: 0.9883 - acc: 0.58 - ETA: 12s - loss: 0.9851 - acc: 0.58 - ETA: 11s - loss: 0.9829 - acc: 0.59 - ETA: 11s - loss: 0.9798 - acc: 0.59 - ETA: 10s - loss: 0.9817 - acc: 0.59 - ETA: 10s - loss: 0.9850 - acc: 0.58 - ETA: 10s - loss: 0.9836 - acc: 0.59 - ETA: 9s - loss: 0.9849 - acc: 0.5910 - ETA: 9s - loss: 0.9872 - acc: 0.588 - ETA: 9s - loss: 0.9863 - acc: 0.588 - ETA: 8s - loss: 0.9825 - acc: 0.590 - ETA: 8s - loss: 0.9794 - acc: 0.592 - ETA: 7s - loss: 0.9755 - acc: 0.595 - ETA: 7s - loss: 0.9768 - acc: 0.595 - ETA: 7s - loss: 0.9790 - acc: 0.594 - ETA: 6s - loss: 0.9773 - acc: 0.596 - ETA: 6s - loss: 0.9771 - acc: 0.596 - ETA: 5s - loss: 0.9766 - acc: 0.595 - ETA: 5s - loss: 0.9780 - acc: 0.595 - ETA: 5s - loss: 0.9759 - acc: 0.597 - ETA: 4s - loss: 0.9750 - acc: 0.598 - ETA: 4s - loss: 0.9723 - acc: 0.600 - ETA: 3s - loss: 0.9723 - acc: 0.600 - ETA: 3s - loss: 0.9699 - acc: 0.602 - ETA: 3s - loss: 0.9709 - acc: 0.601 - ETA: 2s - loss: 0.9728 - acc: 0.601 - ETA: 2s - loss: 0.9714 - acc: 0.601 - ETA: 2s - loss: 0.9704 - acc: 0.601 - ETA: 1s - loss: 0.9710 - acc: 0.600 - ETA: 1s - loss: 0.9698 - acc: 0.599 - ETA: 0s - loss: 0.9702 - acc: 0.599 - ETA: 0s - loss: 0.9698 - acc: 0.601 - ETA: 0s - loss: 0.9685 - acc: 0.601 - 58s 22ms/step - loss: 0.9672 - acc: 0.6025 - val_loss: 1.8101 - val_acc: 0.3113\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.35143\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624/2624 [==============================] - ETA: 48s - loss: 0.4967 - acc: 0.90 - ETA: 49s - loss: 0.6476 - acc: 0.77 - ETA: 49s - loss: 0.7140 - acc: 0.75 - ETA: 49s - loss: 0.6750 - acc: 0.75 - ETA: 48s - loss: 0.7122 - acc: 0.72 - ETA: 48s - loss: 0.6923 - acc: 0.73 - ETA: 48s - loss: 0.6842 - acc: 0.72 - ETA: 47s - loss: 0.7147 - acc: 0.71 - ETA: 47s - loss: 0.7255 - acc: 0.71 - ETA: 47s - loss: 0.7312 - acc: 0.71 - ETA: 46s - loss: 0.7696 - acc: 0.68 - ETA: 46s - loss: 0.7581 - acc: 0.70 - ETA: 45s - loss: 0.7523 - acc: 0.70 - ETA: 45s - loss: 0.7812 - acc: 0.68 - ETA: 45s - loss: 0.7959 - acc: 0.67 - ETA: 44s - loss: 0.7986 - acc: 0.67 - ETA: 44s - loss: 0.7940 - acc: 0.67 - ETA: 43s - loss: 0.7781 - acc: 0.69 - ETA: 43s - loss: 0.7819 - acc: 0.68 - ETA: 43s - loss: 0.7820 - acc: 0.68 - ETA: 42s - loss: 0.7640 - acc: 0.70 - ETA: 42s - loss: 0.7647 - acc: 0.69 - ETA: 41s - loss: 0.7657 - acc: 0.69 - ETA: 41s - loss: 0.7647 - acc: 0.69 - ETA: 41s - loss: 0.7602 - acc: 0.69 - ETA: 40s - loss: 0.7623 - acc: 0.69 - ETA: 40s - loss: 0.7519 - acc: 0.69 - ETA: 40s - loss: 0.7422 - acc: 0.70 - ETA: 39s - loss: 0.7413 - acc: 0.69 - ETA: 39s - loss: 0.7353 - acc: 0.70 - ETA: 38s - loss: 0.7401 - acc: 0.70 - ETA: 38s - loss: 0.7397 - acc: 0.70 - ETA: 38s - loss: 0.7336 - acc: 0.70 - ETA: 37s - loss: 0.7420 - acc: 0.70 - ETA: 37s - loss: 0.7512 - acc: 0.69 - ETA: 37s - loss: 0.7517 - acc: 0.69 - ETA: 36s - loss: 0.7590 - acc: 0.69 - ETA: 36s - loss: 0.7542 - acc: 0.69 - ETA: 35s - loss: 0.7580 - acc: 0.68 - ETA: 35s - loss: 0.7562 - acc: 0.69 - ETA: 35s - loss: 0.7628 - acc: 0.69 - ETA: 34s - loss: 0.7663 - acc: 0.68 - ETA: 34s - loss: 0.7688 - acc: 0.68 - ETA: 33s - loss: 0.7663 - acc: 0.68 - ETA: 33s - loss: 0.7664 - acc: 0.68 - ETA: 33s - loss: 0.7668 - acc: 0.69 - ETA: 32s - loss: 0.7582 - acc: 0.69 - ETA: 32s - loss: 0.7531 - acc: 0.69 - ETA: 31s - loss: 0.7496 - acc: 0.70 - ETA: 31s - loss: 0.7462 - acc: 0.70 - ETA: 31s - loss: 0.7455 - acc: 0.70 - ETA: 30s - loss: 0.7466 - acc: 0.70 - ETA: 30s - loss: 0.7490 - acc: 0.70 - ETA: 29s - loss: 0.7529 - acc: 0.69 - ETA: 29s - loss: 0.7508 - acc: 0.69 - ETA: 29s - loss: 0.7461 - acc: 0.70 - ETA: 28s - loss: 0.7482 - acc: 0.69 - ETA: 28s - loss: 0.7465 - acc: 0.70 - ETA: 28s - loss: 0.7445 - acc: 0.70 - ETA: 27s - loss: 0.7414 - acc: 0.70 - ETA: 27s - loss: 0.7507 - acc: 0.70 - ETA: 26s - loss: 0.7488 - acc: 0.70 - ETA: 26s - loss: 0.7487 - acc: 0.70 - ETA: 26s - loss: 0.7524 - acc: 0.69 - ETA: 25s - loss: 0.7506 - acc: 0.70 - ETA: 25s - loss: 0.7487 - acc: 0.70 - ETA: 24s - loss: 0.7465 - acc: 0.70 - ETA: 24s - loss: 0.7438 - acc: 0.70 - ETA: 24s - loss: 0.7422 - acc: 0.70 - ETA: 23s - loss: 0.7493 - acc: 0.70 - ETA: 23s - loss: 0.7471 - acc: 0.70 - ETA: 22s - loss: 0.7461 - acc: 0.70 - ETA: 22s - loss: 0.7429 - acc: 0.70 - ETA: 22s - loss: 0.7434 - acc: 0.70 - ETA: 21s - loss: 0.7414 - acc: 0.70 - ETA: 21s - loss: 0.7399 - acc: 0.70 - ETA: 21s - loss: 0.7391 - acc: 0.70 - ETA: 20s - loss: 0.7375 - acc: 0.70 - ETA: 20s - loss: 0.7408 - acc: 0.70 - ETA: 19s - loss: 0.7368 - acc: 0.70 - ETA: 19s - loss: 0.7340 - acc: 0.70 - ETA: 19s - loss: 0.7333 - acc: 0.70 - ETA: 18s - loss: 0.7324 - acc: 0.70 - ETA: 18s - loss: 0.7313 - acc: 0.70 - ETA: 17s - loss: 0.7367 - acc: 0.70 - ETA: 17s - loss: 0.7355 - acc: 0.70 - ETA: 17s - loss: 0.7335 - acc: 0.70 - ETA: 16s - loss: 0.7306 - acc: 0.70 - ETA: 16s - loss: 0.7320 - acc: 0.70 - ETA: 15s - loss: 0.7290 - acc: 0.70 - ETA: 15s - loss: 0.7274 - acc: 0.71 - ETA: 15s - loss: 0.7254 - acc: 0.71 - ETA: 14s - loss: 0.7227 - acc: 0.71 - ETA: 14s - loss: 0.7216 - acc: 0.71 - ETA: 14s - loss: 0.7169 - acc: 0.71 - ETA: 13s - loss: 0.7172 - acc: 0.71 - ETA: 13s - loss: 0.7144 - acc: 0.71 - ETA: 12s - loss: 0.7095 - acc: 0.71 - ETA: 12s - loss: 0.7081 - acc: 0.72 - ETA: 12s - loss: 0.7078 - acc: 0.72 - ETA: 11s - loss: 0.7099 - acc: 0.72 - ETA: 11s - loss: 0.7113 - acc: 0.71 - ETA: 10s - loss: 0.7109 - acc: 0.71 - ETA: 10s - loss: 0.7082 - acc: 0.72 - ETA: 10s - loss: 0.7091 - acc: 0.72 - ETA: 9s - loss: 0.7087 - acc: 0.7189 - ETA: 9s - loss: 0.7080 - acc: 0.719 - ETA: 9s - loss: 0.7063 - acc: 0.719 - ETA: 8s - loss: 0.7064 - acc: 0.719 - ETA: 8s - loss: 0.7057 - acc: 0.720 - ETA: 7s - loss: 0.7045 - acc: 0.720 - ETA: 7s - loss: 0.7014 - acc: 0.722 - ETA: 7s - loss: 0.6983 - acc: 0.723 - ETA: 6s - loss: 0.6961 - acc: 0.725 - ETA: 6s - loss: 0.6948 - acc: 0.725 - ETA: 5s - loss: 0.6980 - acc: 0.725 - ETA: 5s - loss: 0.6953 - acc: 0.726 - ETA: 5s - loss: 0.6945 - acc: 0.727 - ETA: 4s - loss: 0.6955 - acc: 0.727 - ETA: 4s - loss: 0.6994 - acc: 0.726 - ETA: 3s - loss: 0.7004 - acc: 0.726 - ETA: 3s - loss: 0.6980 - acc: 0.727 - ETA: 3s - loss: 0.6961 - acc: 0.727 - ETA: 2s - loss: 0.6979 - acc: 0.727 - ETA: 2s - loss: 0.6993 - acc: 0.728 - ETA: 2s - loss: 0.6990 - acc: 0.728 - ETA: 1s - loss: 0.6957 - acc: 0.730 - ETA: 1s - loss: 0.6935 - acc: 0.731 - ETA: 0s - loss: 0.6931 - acc: 0.732 - ETA: 0s - loss: 0.6912 - acc: 0.733 - ETA: 0s - loss: 0.6899 - acc: 0.734 - 58s 22ms/step - loss: 0.6909 - acc: 0.7340 - val_loss: 1.3775 - val_acc: 0.3913\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.35143\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624/2624 [==============================] - ETA: 49s - loss: 0.5530 - acc: 0.85 - ETA: 49s - loss: 0.4514 - acc: 0.90 - ETA: 48s - loss: 0.4974 - acc: 0.86 - ETA: 48s - loss: 0.4496 - acc: 0.85 - ETA: 48s - loss: 0.4228 - acc: 0.86 - ETA: 47s - loss: 0.4123 - acc: 0.87 - ETA: 47s - loss: 0.4303 - acc: 0.86 - ETA: 47s - loss: 0.4331 - acc: 0.86 - ETA: 47s - loss: 0.4817 - acc: 0.84 - ETA: 46s - loss: 0.4878 - acc: 0.83 - ETA: 46s - loss: 0.4911 - acc: 0.83 - ETA: 45s - loss: 0.4909 - acc: 0.83 - ETA: 45s - loss: 0.4931 - acc: 0.83 - ETA: 45s - loss: 0.5074 - acc: 0.82 - ETA: 44s - loss: 0.5061 - acc: 0.82 - ETA: 44s - loss: 0.5001 - acc: 0.82 - ETA: 44s - loss: 0.4936 - acc: 0.82 - ETA: 43s - loss: 0.4883 - acc: 0.82 - ETA: 43s - loss: 0.4780 - acc: 0.83 - ETA: 42s - loss: 0.4727 - acc: 0.83 - ETA: 42s - loss: 0.4731 - acc: 0.83 - ETA: 42s - loss: 0.4820 - acc: 0.82 - ETA: 41s - loss: 0.4893 - acc: 0.82 - ETA: 41s - loss: 0.4981 - acc: 0.82 - ETA: 40s - loss: 0.4899 - acc: 0.82 - ETA: 40s - loss: 0.4911 - acc: 0.82 - ETA: 40s - loss: 0.4962 - acc: 0.81 - ETA: 39s - loss: 0.5000 - acc: 0.81 - ETA: 39s - loss: 0.4949 - acc: 0.82 - ETA: 39s - loss: 0.4919 - acc: 0.82 - ETA: 38s - loss: 0.4869 - acc: 0.82 - ETA: 38s - loss: 0.4849 - acc: 0.82 - ETA: 37s - loss: 0.4838 - acc: 0.82 - ETA: 37s - loss: 0.4807 - acc: 0.82 - ETA: 37s - loss: 0.4765 - acc: 0.82 - ETA: 36s - loss: 0.4813 - acc: 0.81 - ETA: 36s - loss: 0.4756 - acc: 0.82 - ETA: 36s - loss: 0.4736 - acc: 0.82 - ETA: 35s - loss: 0.4819 - acc: 0.81 - ETA: 35s - loss: 0.4824 - acc: 0.81 - ETA: 34s - loss: 0.4795 - acc: 0.81 - ETA: 34s - loss: 0.4819 - acc: 0.81 - ETA: 34s - loss: 0.4812 - acc: 0.81 - ETA: 33s - loss: 0.4815 - acc: 0.81 - ETA: 33s - loss: 0.4828 - acc: 0.81 - ETA: 32s - loss: 0.4758 - acc: 0.81 - ETA: 32s - loss: 0.4722 - acc: 0.81 - ETA: 32s - loss: 0.4704 - acc: 0.81 - ETA: 31s - loss: 0.4709 - acc: 0.82 - ETA: 31s - loss: 0.4727 - acc: 0.82 - ETA: 31s - loss: 0.4743 - acc: 0.82 - ETA: 30s - loss: 0.4723 - acc: 0.82 - ETA: 30s - loss: 0.4704 - acc: 0.82 - ETA: 29s - loss: 0.4709 - acc: 0.82 - ETA: 29s - loss: 0.4660 - acc: 0.82 - ETA: 29s - loss: 0.4609 - acc: 0.82 - ETA: 28s - loss: 0.4584 - acc: 0.82 - ETA: 28s - loss: 0.4587 - acc: 0.82 - ETA: 27s - loss: 0.4598 - acc: 0.82 - ETA: 27s - loss: 0.4591 - acc: 0.82 - ETA: 27s - loss: 0.4630 - acc: 0.82 - ETA: 26s - loss: 0.4667 - acc: 0.82 - ETA: 26s - loss: 0.4658 - acc: 0.82 - ETA: 26s - loss: 0.4626 - acc: 0.82 - ETA: 25s - loss: 0.4668 - acc: 0.82 - ETA: 25s - loss: 0.4674 - acc: 0.82 - ETA: 24s - loss: 0.4687 - acc: 0.82 - ETA: 24s - loss: 0.4714 - acc: 0.82 - ETA: 24s - loss: 0.4735 - acc: 0.82 - ETA: 23s - loss: 0.4730 - acc: 0.82 - ETA: 23s - loss: 0.4728 - acc: 0.82 - ETA: 22s - loss: 0.4712 - acc: 0.82 - ETA: 22s - loss: 0.4693 - acc: 0.82 - ETA: 22s - loss: 0.4666 - acc: 0.82 - ETA: 21s - loss: 0.4668 - acc: 0.82 - ETA: 21s - loss: 0.4632 - acc: 0.82 - ETA: 21s - loss: 0.4672 - acc: 0.82 - ETA: 20s - loss: 0.4672 - acc: 0.82 - ETA: 20s - loss: 0.4682 - acc: 0.82 - ETA: 19s - loss: 0.4649 - acc: 0.82 - ETA: 19s - loss: 0.4622 - acc: 0.82 - ETA: 19s - loss: 0.4635 - acc: 0.82 - ETA: 18s - loss: 0.4626 - acc: 0.82 - ETA: 18s - loss: 0.4623 - acc: 0.82 - ETA: 17s - loss: 0.4621 - acc: 0.82 - ETA: 17s - loss: 0.4606 - acc: 0.82 - ETA: 17s - loss: 0.4623 - acc: 0.82 - ETA: 16s - loss: 0.4617 - acc: 0.82 - ETA: 16s - loss: 0.4600 - acc: 0.82 - ETA: 15s - loss: 0.4631 - acc: 0.82 - ETA: 15s - loss: 0.4623 - acc: 0.82 - ETA: 15s - loss: 0.4597 - acc: 0.82 - ETA: 14s - loss: 0.4557 - acc: 0.82 - ETA: 14s - loss: 0.4526 - acc: 0.83 - ETA: 14s - loss: 0.4512 - acc: 0.83 - ETA: 13s - loss: 0.4516 - acc: 0.83 - ETA: 13s - loss: 0.4531 - acc: 0.82 - ETA: 12s - loss: 0.4520 - acc: 0.83 - ETA: 12s - loss: 0.4556 - acc: 0.82 - ETA: 12s - loss: 0.4564 - acc: 0.82 - ETA: 11s - loss: 0.4558 - acc: 0.82 - ETA: 11s - loss: 0.4590 - acc: 0.82 - ETA: 10s - loss: 0.4582 - acc: 0.82 - ETA: 10s - loss: 0.4569 - acc: 0.82 - ETA: 10s - loss: 0.4563 - acc: 0.82 - ETA: 9s - loss: 0.4567 - acc: 0.8283 - ETA: 9s - loss: 0.4547 - acc: 0.829 - ETA: 9s - loss: 0.4550 - acc: 0.828 - ETA: 8s - loss: 0.4539 - acc: 0.828 - ETA: 8s - loss: 0.4533 - acc: 0.828 - ETA: 7s - loss: 0.4506 - acc: 0.829 - ETA: 7s - loss: 0.4502 - acc: 0.829 - ETA: 7s - loss: 0.4485 - acc: 0.830 - ETA: 6s - loss: 0.4505 - acc: 0.828 - ETA: 6s - loss: 0.4498 - acc: 0.829 - ETA: 5s - loss: 0.4497 - acc: 0.828 - ETA: 5s - loss: 0.4494 - acc: 0.829 - ETA: 5s - loss: 0.4471 - acc: 0.830 - ETA: 4s - loss: 0.4484 - acc: 0.829 - ETA: 4s - loss: 0.4470 - acc: 0.829 - ETA: 3s - loss: 0.4468 - acc: 0.828 - ETA: 3s - loss: 0.4463 - acc: 0.829 - ETA: 3s - loss: 0.4459 - acc: 0.829 - ETA: 2s - loss: 0.4459 - acc: 0.830 - ETA: 2s - loss: 0.4472 - acc: 0.829 - ETA: 2s - loss: 0.4457 - acc: 0.830 - ETA: 1s - loss: 0.4448 - acc: 0.831 - ETA: 1s - loss: 0.4429 - acc: 0.832 - ETA: 0s - loss: 0.4415 - acc: 0.832 - ETA: 0s - loss: 0.4395 - acc: 0.833 - ETA: 0s - loss: 0.4403 - acc: 0.834 - 58s 22ms/step - loss: 0.4401 - acc: 0.8342 - val_loss: 1.5168 - val_acc: 0.5053\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.35143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28b1c8d0ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 34.8000%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted diagnosis for each image in test set\n",
    "diagnosis_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(diagnosis_predictions)==np.argmax(test_targets, axis=1))/len(diagnosis_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step N: Create a CNN to Classify Diagnosis (using Transfer Learning)\n",
    "\n",
    "\n",
    "- [VGG-19](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG19Data.npz) bottleneck features\n",
    "- [ResNet-50](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz) bottleneck features\n",
    "- [Inception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogInceptionV3Data.npz) bottleneck features\n",
    "- [Xception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz) bottleneck features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "\n",
    "ResNet50_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = ResNet50_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(200, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "\n",
    "#x = ResNet50_model.output\n",
    "#x = Conv2D(filters=75, kernel_size=2, padding='same', activation='relu', input_shape=(224,224,3))(x)\n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=100, kernel_size=1, padding='same', activation='relu')(x)\n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=125, kernel_size=1, padding='same', activation='relu')(x)    \n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=125, kernel_size=1, padding='same', activation='relu')(x)   \n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=125, kernel_size=1, padding='same', activation='relu')(x)   \n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=125, kernel_size=1, padding='same', activation='relu')(x)    \n",
    "#x = MaxPooling2D(pool_size=2)(x)    \n",
    "#x = Conv2D(filters=125, kernel_size=1, padding='same', activation='relu')(x)    \n",
    "#x = MaxPooling2D(pool_size=2)(x)\n",
    "#x = Dropout(0.3)(x)\n",
    "##x = Flatten()(x)\n",
    "#predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this is the model we will train\n",
    "ResNet50_transfer_model = Model(inputs=ResNet50_model.input, outputs=predictions)\n",
    "\n",
    "### first: train only the top layers (which were randomly initialized)\n",
    "### i.e. freeze all convolutional InceptionV3 layers\n",
    "##for layer in ResNet50_model.layers:\n",
    "##    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "ResNet50_transfer_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2624 samples, validate on 938 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "ResNet50_epochs = 10\n",
    "\n",
    "ResNet50_checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.ResNet50.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "ResNet50_transfer_model.fit(train_tensors, train_targets, \n",
    "                            validation_data=(valid_tensors, valid_targets),\n",
    "                            epochs=ResNet50_epochs, batch_size=20, callbacks=[ResNet50_checkpointer], verbose=1)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(ResNet50_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "#### we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "#### the first 249 layers and unfreeze the rest:\n",
    "###for layer in ResNet50_transfer_model.layers[:174]:\n",
    "###   layer.trainable = False\n",
    "###for layer in ResNet50_transfer_model.layers[174:]:\n",
    "###   layer.trainable = True\n",
    "\n",
    "###ResNet50_transfer_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "####model.summary()\n",
    "###\n",
    "#### we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "#### alongside the top Dense layers\n",
    "###ResNet50_transfer_model.fit(train_tensors, train_targets, \n",
    "###          validation_data=(valid_tensors, valid_targets),\n",
    "###          epochs=ResNet50_epochs, batch_size=20, callbacks=[ResNet50_checkpointer], verbose=1)\n",
    "###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy# load t \n",
    "model.load_weights('saved_models/weights.best.ResNet50.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n\\\\CNV', 'n\\\\DME', 'n\\\\DRUSEN', 'n\\\\NORMAL']\n",
      "OCT2017-REDUCED/test\\CNV\\CNV-451136-7.jpeg\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "#return ResNet50(weights='imagenet', include_top=False).predict(preprocess_input(tensor))\n",
    "\n",
    "\n",
    "def transfer_learning_model_make_prediction(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = preprocess_input(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return np.argmax(predicted_vector)\n",
    "\n",
    "\n",
    "file_to_test = test_files[800]\n",
    "\n",
    "print(oct_names)\n",
    "print(file_to_test)\n",
    "print(transfer_learning_model_make_prediction(file_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Test accuracy: 42.4000%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(test_targets)\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "transfer_learning_model_predictions = [transfer_learning_model_make_prediction(file) for file in test_files]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(transfer_learning_model_predictions)==np.argmax(test_targets, axis=1))/len(transfer_learning_model_predictions)\n",
    "\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
